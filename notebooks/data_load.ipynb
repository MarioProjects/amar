{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maparla/anaconda3/envs/ama-dev/lib/python3.12/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from src.processing.readers import PDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maparla/anaconda3/envs/ama-dev/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading detection model vikp/surya_det2 on device cpu with dtype torch.float32\n",
      "Loading recognition model vikp/surya_rec on device cpu with dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "ENABLE_OCR = True\n",
    "pdf_reader = PDFReader(enable_ocr=ENABLE_OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n",
      "Recognizing Text:   0%|          | 0/2 [00:00<?, ?it/s]/home/maparla/anaconda3/envs/ama-dev/lib/python3.12/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "Recognizing Text: 100%|██████████| 2/2 [01:00<00:00, 30.29s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:04<00:00,  4.57s/it]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:28<00:00, 14.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Scanned PDF example\n",
    "pdf_path = \"notebooks/examples/analogic.pdf\"\n",
    "scanned_info = pdf_reader.get_text(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First page of the scanned PDF:\n",
      "\n",
      "June 5, 1984\n",
      "MEMORANDUM\n",
      "10:\n",
      "Samuel D. Chilcote,\n",
      "Jr.\n",
      "FR:\n",
      "Peter G. Sparber/\n",
      "RE:\n",
      "Convenience Stores\n",
      "--\n",
      "Some time ago you asked that we consider the feasibility of\n",
      "working closer with the convenience store industry. As you\n",
      "then suspected, there is significant potential for coopera¬\n",
      "tion.\n",
      "Attached is a booklet containing a good deal of background\n",
      "information on the convenience store industry including\n",
      "material on the industry's major association, its largest\n",
      "20 chains, its most important issues and its dependence on\n",
      "tobacco products. The booklet also describes efforts - many\n",
      "of which are already under way -- to improve our relationship\n",
      "with the convenience store industry.\n",
      "If you agree, we will distribute copies of this booklet to\n",
      "all field staff and others with issues responsibilities.\n",
      ". We\n",
      "will also begin implementation of all projects not already\n",
      "in progress.\n",
      "We found this exercise to be quite worthwhile. Therefore,\n",
      "we are proceeding with similar booklets on the grocery and\n",
      "restaurant industries and are considering others in the near\n",
      "future.\n",
      "/mb\n",
      "attachment\n",
      "Bill Kloepfer\n",
      "Howard Liebengood\n",
      "Dan Milway\n",
      "Roger Mozingo\n",
      "TIOK 0022818\n"
     ]
    }
   ],
   "source": [
    "print(f\"First page of the scanned PDF:\\n\\n{scanned_info[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digital PDF example\n",
    "pdf_path = \"notebooks/examples/digital.pdf\"\n",
    "digital_info = pdf_reader.get_text(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First page of the digital PDF:\n",
      "\n",
      "Sigmoid Loss for Language Image Pre-Training\n",
      "Xiaohua Zhai⋆\n",
      "Basil Mustafa\n",
      "Alexander Kolesnikov\n",
      "Lucas Beyer⋆\n",
      "Google DeepMind, Z¨\n",
      "urich, Switzerland\n",
      "{xzhai, basilm, akolesnikov, lbeyer}@google.com\n",
      "Abstract\n",
      "We propose a simple pairwise Sigmoid loss\n",
      "for\n",
      "Language-Image Pre-training (SigLIP). Unlike standard\n",
      "contrastive learning with softmax normalization, the sig-\n",
      "moid loss operates solely on image-text pairs and does not\n",
      "require a global view of the pairwise similarities for nor-\n",
      "malization.\n",
      "The sigmoid loss simultaneously allows fur-\n",
      "ther scaling up the batch size, while also performing bet-\n",
      "ter at smaller batch sizes. Combined with Locked-image\n",
      "Tuning, with only four TPUv4 chips, we train a SigLiT\n",
      "model that achieves 84.5% ImageNet zero-shot accuracy\n",
      "in two days. The disentanglement of the batch size from\n",
      "the loss further allows us to study the impact of exam-\n",
      "ples vs pairs and negative to positive ratio.\n",
      "Finally, we\n",
      "push the batch size to the extreme, up to one million, and\n",
      "ﬁnd that the beneﬁts of growing batch size quickly dimin-\n",
      "ish, with a more reasonable batch size of 32 k being suf-\n",
      "ﬁcient.\n",
      "We release our models at https://github.\n",
      "com/google-research/big_vision and hope our\n",
      "research motivates further explorations in improving the\n",
      "quality and efﬁciency of language-image pre-training.\n",
      "1. Introduction\n",
      "Contrastive pre-training using weak supervision from\n",
      "image-text pairs found on the web is becoming the go-to\n",
      "method for obtaining generic computer vision backbones,\n",
      "slowly replacing pre-training on large labelled multi-class\n",
      "datasets.\n",
      "The high-level idea is to simultaneously learn\n",
      "an aligned representation space for images and texts using\n",
      "paired data. Seminal works CLIP [36] and ALIGN [23] es-\n",
      "tablished the viability of this approach at a large scale, and\n",
      "following their success, many large image-text datasets be-\n",
      "came available privately [59, 13, 21, 49] and publicly [40,\n",
      "6, 15, 7, 41].\n",
      "The standard recipe to pre-train such models leverages\n",
      "the image-text contrastive objective. It aligns the image and\n",
      "⋆equal contribution\n",
      "Table 1: SigLiT and SigLIP results. Sigmoid loss is mem-\n",
      "ory efﬁcient, allows larger batch sizes (BS) that unlocks\n",
      "language image pre-training with a small number of chips.\n",
      "SigLiT model with a frozen public\n",
      "B/8 checkpoint [42],\n",
      "trained on the LiT image-text dataset [59] using four TPU-\n",
      "v4 chips for one day, achieves 79.7% 0-shot accuracy on\n",
      "ImageNet.\n",
      "The same setup with a g/14 checkpoint [58]\n",
      "leads to 84.5% accuracy, trained for two days. With a pub-\n",
      "lic unlocked\n",
      "B/16 image checkpoint [42], trained on the\n",
      "WebLI dataset [13], SigLIP achieves 71.0% 0-shot accu-\n",
      "racy using 16 TPU-v4 chips for three days. The last two\n",
      "rows show results with randomly initialized models.\n",
      "Image\n",
      "Text\n",
      "BS\n",
      "#TPUv4 Days\n",
      "INet-0\n",
      "SigLiT\n",
      "B/8\n",
      "L∗\n",
      "32 k\n",
      "4\n",
      "1\n",
      "79.8\n",
      "SigLiT\n",
      "g/14\n",
      "L\n",
      "20 k\n",
      "4\n",
      "2\n",
      "84.5\n",
      "SigLIP\n",
      "B/16\n",
      "B\n",
      "16 k\n",
      "16\n",
      "3\n",
      "71.0\n",
      "SigLIP\n",
      "B/16\n",
      "B\n",
      "32 k\n",
      "32\n",
      "2\n",
      "72.1\n",
      "SigLIP\n",
      "B/16\n",
      "B\n",
      "32 k\n",
      "32\n",
      "5\n",
      "73.4\n",
      "∗We use a variant of the L model with 12 layers.\n",
      "text embeddings for matching (positive) image-text pairs\n",
      "while making sure that unrelated (negative) image-text pairs\n",
      "are dissimilar in the embedding space. This is achieved via a\n",
      "batch-level softmax-based contrastive loss, applied twice to\n",
      "normalize the pairwise similarity scores across all images,\n",
      "then all texts. A naive implementation of the softmax is\n",
      "numerically unstable; it is usually stabilized by subtracting\n",
      "the maximum input value before applying the softmax [18],\n",
      "which requires another pass over the full batch.\n",
      "In this paper, we propose a simpler alternative: the sig-\n",
      "moid loss. It does not require any operation across the full\n",
      "batch and hence greatly simpliﬁes the distributed loss im-\n",
      "plementation and boosts efﬁciency. Additionally, it con-\n",
      "ceptually decouples the batch size from the deﬁnition of\n",
      "the task. We compare the proposed sigmoid loss with the\n",
      "standard softmax loss across multiple setups.\n",
      "In partic-\n",
      "ular, we investigate sigmoid-based loss with two promi-\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"First page of the digital PDF:\\n\\n{digital_info[0].text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ama-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
